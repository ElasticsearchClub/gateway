path.data: data
path.logs: log

#log.level: trace
#log.debug: true

entry:
  - name: my_es_entry
    enabled: true
    router: my_router
    network:
      binding: 0.0.0.0:8000
#    tls:
#      enabled: true

flow:
  - name: cache_first
    filter: #comment out any filter sections, like you don't need cache or rate-limiter
#      - name: sleep
#        parameters:
#          sleep_in_million_seconds: 1024
#      - name: request_body_regex_replace
#        parameters:
#          pattern: '"size": 10000'
#          to: '"size": 100'
      - name: get_cache
        parameters:
          pass_patterns:
            - _cat
      - name: date_range_precision_tuning
        parameters:
          time_precision: 4
          path_keywords:
            - _search
            - _async_search
      - name: get_cache
        parameters:
          pass_patterns:
            - _cat
      - name: elasticsearch
        parameters:
          elasticsearch: dev  #elasticsearch configure reference name
          max_connection: 1000 #max tcp connection to upstream, default for all nodes
          max_response_size: -1 #default for all nodes
          balancer: weight
          refresh: # refresh upstream nodes list, need to enable this feature to use elasticsearch nodes auto discovery
            enabled: true
            interval: 60s
          filter:
            tags:
                exclude:
                - a: b
            roles:
              exclude:
                - master
#      - name: response_body_regex_replace
#        parameters:
#          pattern: '"took":\d+,'
#          to: '"took":123,'
      - name: set_cache
        parameters:
          cache_ttl: 10s
  - name: online_indexing_merge
    filter:
#      - name: bulk_to_queue
#        parameters:
#          elasticsearch: dev
      - name: bulk_reshuffle
        parameters:
          elasticsearch: dev
          level: node
#          level: shard
          mode: async
#          mode: sync
          safety_parse: true
          valid_metadata: true
#          shards:
#            - "0"
#            - "5"
#            - "9"
      - name: elasticsearch
        parameters:
          elasticsearch: dev
          refresh:
            enabled: true
            interval: 30s
  - name: request_logging # this flow is used for request logging, refer to `router`'s `tracing_flow`
    filter:
      - name: request_logging
        parameters:
          queue_name: request_logging
          max_request_body_size: 1024
          max_response_body_size: 1024
          min_elapsed_time_in_ms: 500 # only record slow requests
router:
  - name: my_router
    default_flow: cache_first
#    tracing_flow: request_logging
    rules:
      - method:
          - "POST"
        pattern:
          - /_bulk
        flow:
          - online_indexing_merge
elasticsearch:
- name: dev
  enabled: true
  endpoint: http://localhost:9200 # if your elasticsearch is using https, your gateway should be listen on as https as well
  traffic_control:
    max_bytes_per_node: 52428800 #50MB per node
#    max_qps_per_node: 10 #max bulk requests per node
  basic_auth: #used to discovery full cluster nodes, or check elasticsearch's health and versions
    username: elastic
    password: pass
  discovery: # auto discovery elasticsearch cluster nodes
    enabled: true
    refresh:
      enabled: true
      interval: 60s

modules:
- name: elastic
  enabled: true
  elasticsearch: dev
  store:
    enabled: true
  monitoring:
    enabled: false
  orm:
    enabled: true
    init_template: true
    template_name: ".gateway-default"
    index_prefix: "gateway_"

- name: pipeline
  enabled: true
  runners:
    - name: primary
      enabled: true
      max_go_routine: 1
      threshold_in_ms: 0
      timeout_in_ms: 5000
      pipeline_id: request_logging_index
    - name: nodes_index
      enabled: true
      max_go_routine: 1
      threshold_in_ms: 0
      timeout_in_ms: 5000
      pipeline_id: bulk_request_ingest
    - name: bulk_reshuffle
      enabled: false
      max_go_routine: 1
      threshold_in_ms: 0
      timeout_in_ms: 5000
      pipeline_id: bulk_reshuffle


pipelines:
- name: request_logging_index
  start:
    joint: json_indexing
    enabled: true
    parameters:
      index_name: "gateway_requests"
      elasticsearch: "dev"
      input_queue: "request_logging"
      timeout: "1s"
      worker_size: 1
      bulk_size_in_mb: 1 #in MB
- name: bulk_reshuffle
  start:
    joint: bulk_reshuffle
    enabled: true
    parameters:
      elasticsearch: "dev"
      timeout: "1s"
      worker_size: 1
      bulk_size_in_mb: 1 #in MB
      level: shard
      mode: async
- name: bulk_request_ingest
  start:
    joint: bulk_indexing
    enabled: true
    parameters:
      elasticsearch: "dev"
      compress: true
      timeout: "5s"
      worker_size: 1
      bulk_size_in_mb: 5  #in MB
#      bulk_size_in_kb: 20  #in KB
      retry_delay_in_second: 5
      warm_retry_message: false
      log_bulk_message: false
      error_message_truncate_size: 1024
      dead_letter_queue: "failed_bulk_messages"
#      shards: #specify which shards are enabled
#        - "0"
#        - "5"
#        - "9"
#      index:
#        - test2
#        - test6

#floating_ip:
#  enabled: true
#  ip: 192.168.3.234      #yep, it's optional, infini-gateway could detect one but maybe not the right one
##  netmask: 255.255.255.0 #optional
##  interface: en1         #optional
#statsd:
#  enabled: false
#  host: 192.168.3.98
#  port: 8125
#  namespace: gateway.
#forcemerge:
#  enabled: false
#  elasticsearch: dev
#  min_num_segments: 1
#  max_num_segments: 1
#  indices:
#    - index_name

queue:
  min_msg_size: 1
  max_msg_size: 1000000000
  max_bytes_per_file: 1073741824
  sync_every_records: 1000 # sync by records count
  sync_timeout_in_ms: 1000 # sync by time in million seconds
  write_chan_buffer: 0
  read_chan_buffer: 0
