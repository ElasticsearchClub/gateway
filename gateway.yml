path.data: data
path.logs: log

entry:
  - name: es_gateway #your gateway endpoint
    enabled: true
#    router: default #configure your gateway's routing flow
    router: not_found #configure your gateway's routing flow
    network:
      binding: 0.0.0.0:8000
#      skip_occupied_port: false
      reuse_port: true #you can start multi gateway instance, they share same port, to full utilize system's resources
    tls:
      enabled: false #if your es is using https, the gateway entrypoint should enable https too

flow:
#  - name: not_found #testing flow
#    filter:
#      - name: not_found
#        type: echo
#        parameters:
#          str: '404 not found\n'
#          repeat: 1
#  - name: cache_first
#    filter: #comment out any filter sections, like you don't need cache or rate-limiter
#      - name: get_cache_1
#        type: get_cache
#        parameters:
#          pass_patterns: ["_cat","scroll", "scroll_id","_refresh","_cluster","_ccr","_count","_flush","_ilm","_ingest","_license","_migration","_ml","_rollup","_data_stream","_open", "_close"]
##          hash_factor:
##            header:
##              - "*"
##            path: true
##            query_args:
##              - id
##          must_cache:
##            method:
##              - GET
##            path:
##              - _search
##              - _async_search
#      - name: rate_limit_1
#        type: rate_limit
#        parameters:
#          message: "Hey, You just reached our request limit!"
#          rules: #configure match rules against request's PATH, eg: /_cluster/health, match the first rule and return
#            - pattern: "/(?P<index_name>medcl)/_search" #use index name, will match: /medcl/_search, with limit medcl with max_qps ~=3
#              max_qps: 3 #setting max qps after match
#              group: index_name #use regex group name to extract the throttle bucket name
#            - pattern: "/(?P<index_name>.*?)/_search" #use regex pattern to match index, will match any /$index/_search, and limit each index with max_qps ~=100
#              max_qps: 100
#              group: index_name
#      - name: elasticsearch_1
#        type: elasticsearch
#        parameters:
##          elasticsearch: prod  #elasticsearch configure reference name
#          elasticsearch: default  #elasticsearch configure reference name
#          max_connection: 1000 #max tcp connection to upstream, default for all nodes
#          max_response_size: -1 #default for all nodes
#          balancer: weight
##          weight: #overwride host's weight, the default weight is 1
##            - host: 192.168.3.201:9200 #the format is host:port
##              weight: 10
##            - host: 192.168.3.202:9200
##              weight: 20
##            - host: 192.168.3.203:9200
##              weight: 30
##            - host: 192.168.3.199:9200
##              weight: 3
#          discovery:
#            enabled: true
##            auto_update: true
##            auto_update_interval: 10s
#      - name: set_cache_1
#        type: set_cache
##        parameters:
##          min_response_size: 100
##          max_response_size: 1024000
##          cache_ttl: 10s
##          max_cache_items: 100000
  - name: request_logging # this flow is used for request logging, refer to `router`'s `tracing_flow`
    filter:
      - name: sample_1
        type: sample
        parameters:
          ratio: 0.1
      - name: request_path_filter_1
        type: request_path_filter
        parameters:
#          must: #must match all rules to continue
#            prefix:
#              - /medcl
#            contain:
#              - _search
#            suffix:
#              - _count
#              - _refresh
#            wildcard:
#              - /*/_refresh
#            regex:
#              - ^/m[\w]+dcl
#          must_not: # any match will be filtered
#            prefix:
#              - /medcl
#            contain:
#              - _search
#            suffix:
#              - _count
#              - _refresh
#            wildcard:
#              - /*/_refresh
#            regex:
#              - ^/m[\w]+dcl
          should:
#            prefix:
#              - /medcl
            contain:
              - _search
              - _async_search
#            suffix:
#              - _refresh
#            wildcard:
#              - /*/_refresh
#            regex:
#              - ^/m[\w]+dcl
#      - name: request_header_filter1 # filter out the requests that we are not interested, reduce tracing pressure
#        type: request_header_filter
#        parameters:
#          exclude: # any rule match will marked request as filtered
#          - ENV: test #for example, requests for testing purpose can be filtered, eg: curl localhost:8000 -H "ENV: test"
#          - INFINI-CACHE: CACHED # cached requests can be filtered safely
#          include: # any match will marked as pass through, when include was specified but none of these rules are matched, the request will be mark as filtered, the next filters won't continue processing
#          - TRACE: true # curl localhost:8000 -H "TRACE: true"
#          - TRACING: true # curl localhost:8000 -H "TRACING: true"
#      - name: request_method_filter
#        type: request_method_filter
#        parameters:
#          exclude:
#            - PUT
#            - POST
#          include:
#            - GET
#            - HEAD
#            - DELETE
#      - name: request_logging_1
#        type: request_logging
#        parameters:
#          queue_name: request_logging


router:
  - name: default
    tracing_flow: request_logging #a flow will execute after request finish
    default_flow: cache_first
    rules: #rules can't be conflicted with each other, will be improved in the future
      - id: 1 # this rule means match every requests, and sent to `cache_first` flow
        method:
          - "*"
        pattern:
          - /
#        priority: 1
        flow:
          - cache_first # after match, which processing flow will go through
  - name: not_found
#    tracing_flow: request_logging
#    default_flow: not_found
    default_flow: request_logging

elasticsearch:
- name: default
  enabled: true
  endpoint: http://localhost:9200 # if your elasticsearch is using https, your gateway should be listen on as https as well
  version: 7.6.0 #optional, used to select es adaptor, can be done automatically after connect to es
  index_prefix: gateway_
  basic_auth: #used to discovery full cluster nodes, or check elasticsearch's health and versions
    username: elastic
    password: pass
#- name: prod
#  enabled: true
#  endpoint: http://192.168.3.201:9200 # if your elasticsearch is using https, your gateway should be listen on as https as well
#  basic_auth: #used to discovery full cluster nodes, or check elasticsearch's health and versions
#    username: elastic
#    password: pass

modules:
- name: elastic
  enabled: true
  elasticsearch: default
  init_template: true
- name: pipeline
  enabled: true
  runners:
    - name: primary
      enabled: true
      max_go_routine: 1
      threshold_in_ms: 0
      timeout_in_ms: 5000
      pipeline_id: request_logging_index


pipelines:
- name: request_logging_index
  start:
    joint: json_indexing
    enabled: true
    parameters:
      index_name: "gateway_requests"
      elasticsearch: "default"
      input_queue: "request_logging"
      timeout: "60s"
      worker_size: 1
      bulk_size_in_mb: 10 #in MB
  process: []


queue:
  min_msg_size: 1
  max_msg_size: 50000000
  max_bytes_per_file: 53687091200
  sync_every_records: 100000 # sync by records count
  sync_timeout_in_ms: 10000 # sync by time in million seconds
  read_chan_buffer: 0

statsd:
  enabled: true
  host: 127.0.0.1
  port: 8125
  namespace: gateway.
