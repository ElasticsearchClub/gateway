path.data: data
path.logs: log

entry:
  - name: my_es_entry
    enabled: true
    router: my_router
    max_concurrency: 10000
    network:
      binding: 0.0.0.0:8010
    tls:
      enabled: false
flow:
  - name: prod-flow-post-processing
    filter_v2:
      - set_basic_auth: #覆盖身份信息
          username: elastic
          password: password
      - if:
          cluster_available: ["prod"]
        then:
          - elasticsearch:
              elasticsearch: "prod"
              max_connection_per_host: 1000
          - bulk_response_validate:
              invalid_status: 500
          - if:
              in:
                _ctx.response.status: [ 403,404,200,201 ]
            then:
              - set_basic_auth: #覆盖dr1身份信息
                  username: elastic
                  password: password
              - disk_enqueue:
                  queue_name: "dr1"
              - set_basic_auth: #覆盖dr2身份信息
                  username: elastic
                  password: password
              - disk_enqueue:
                  queue_name: "dr2"
            else:
              - disk_enqueue:
                  queue_name: "prod-500"
        else:
          - disk_enqueue:
              queue_name: "prod-500"
          - sleep:
              sleep_in_million_seconds: 1000
          - elasticsearch_health_check:
              elasticsearch: "prod"
      #- sample:
      #    ratio: 0.1
      - flow:
          flows:
            - request_logging
  - name: prod-flow
    filter_v2:
      - set_basic_auth: #覆盖身份信息
          username: elastic
          password: password
      - if:
          and:
            - queue_has_lag: [ "prod", "prod-500" ]
            - cluster_available: ["prod"]
        then: #集群可用但是集群有堆积的情况，先入队列，追加到队尾，确保操作顺序的一致性
          - disk_enqueue:
              queue_name: "prod"
          - set_basic_auth: #覆盖dr1身份信息
              username: elastic
              password: password
          - disk_enqueue:
              queue_name: "dr1"
          - set_basic_auth: #覆盖dr2身份信息
              username: elastic
              password: password
          - disk_enqueue:
              queue_name: "dr2"
          - set_response:
              status: 202
              body: "202 Accepted"
        else: # 集群不可用或者集群可用且没有堆积的情况，都直接转发给集群先处理
          - if: #集群如果已经变成不可用状态，则直接丢弃请求，让客户端选择处理，或者也可落地队列确保不丢数据
              not:
                cluster_available: ["prod"]
            then: #如果集群不可用，则直接拒绝客户端请求
              - set_response:
                  status: 503
                  body: "503 Service Unavailable"
              - elasticsearch_health_check: #由请求触发的限速模式下的主动检查后端监控情况
                  elasticsearch: "prod"
              - drop:
#          - translog:
#          - set_request_header: #覆盖 Header 信息
#              headers:
#                - Trial -> true
#                - Department -> Engineering
#          - set_hostname: #覆盖域名主机信息
#              hostname: api.infini.sh
          - elasticsearch: #集群可用，直接处理请求
              elasticsearch: "prod"
              max_connection_per_host: 1000
          - bulk_response_validate: #如果是 bulk 请求，还需要进一步验证是否存在部分请求失败的错误异常
              invalid_status: 507
          - if: #验证主集群的操作是否成功写入
              in:
                _ctx.response.status: [ 403,404,200,201 ]
            then: #仅正常处理的集群才转发给后端集群
              - set_basic_auth: #覆盖dr1身份信息
                  username: elastic
                  password: password
              - disk_enqueue:
                  queue_name: "dr1"            
              - set_basic_auth: #覆盖dr2身份信息
                  username: elastic
                  password: password
              - disk_enqueue:
                  queue_name: "dr2"
            else: #集群可用的情况下但是失败了，可能存在脏写，将请求放入写入失败队列，后续可以选择两边集群都重做一次，最终确保一致性，写 translog，后续提供 UI 可以进行三方检查：主、备集群和本地日志
              - disk_enqueue:
                  queue_name: "prod-500"
  - name: cache_first
    filter: #comment out any filter sections, like you don't need cache or rate-limiter
      - name: get_cache
        parameters:
          pass_patterns:
            - _cat
      - name: elasticsearch
        parameters:
          elasticsearch: prod  #elasticsearch configure reference name
          max_connection_per_host: 1000 #max tcp connection to upstream, default for all nodes
          max_response_size: -1 #default for all nodes
          balancer: weight
          refresh: # refresh upstream nodes list, need to enable this feature to use elasticsearch nodes auto discovery
            enabled: true
            interval: 60s
          filter:
            tags:
              exclude:
                - temp: cold
            roles:
              exclude:
                - master
      - name: set_cache
        parameters:
          cache_ttl: 10s
  - name: request_logging # this flow is used for request logging, refer to `router`'s `tracing_flow`
    filter:
      - name: request_path_filter
        parameters:
          must_not:
            prefix:
              - /favicon.ico    
      - name: request_logging
        parameters:
          queue_name: request_logging
          max_request_body_size: 1024
          max_response_body_size: 1024
          #          min_elapsed_time_in_ms: 500 # only record slow requests
          bulk_stats_details: true
router:
  - name: my_router
    default_flow: prod-flow
    tracing_flow: request_logging
    
    
elasticsearch:
- name: prod #主
  enabled: true
  version: 6.8.7
  endpoint: http://172.26.9.32:9201
  discovery: 
    enabled: true
    refresh:
      enabled: true
  basic_auth: 
    username: elastic
    password: password
- name: dr1 #备1
  enabled: true
  version: 7.9.2
  endpoint: http://172.26.9.47:9202
  discovery: 
    enabled: true
    refresh:
      enabled: true
  basic_auth: 
    username: elastic
    password: password
- name: dr2 #备2
  enabled: true
  version: 6.8.7
  endpoint: http://172.26.9.44:9212
  discovery: 
    enabled: true
    refresh:
      enabled: true
  basic_auth: 
    username: elastic
    password: password

flow_runner:
  enabled: true
  input_queue: "prod-500"
  flow: prod-flow-post-processing

pipelines:
  - name: disk_queue_consumer-dr1
    enabled: true
    start:
      joint: disk_queue_consumer
      enabled: true
      parameters:
        input_queue: "dr1"
        elasticsearch: "dr1"
        waiting_after: [ "dr1-500"]
        timeout: "1s"
        worker_size: 20
  - name: disk_queue_consumer-dr2
    enabled: true
    start:
      joint: disk_queue_consumer
      enabled: true
      parameters:
        input_queue: "dr2"
        elasticsearch: "dr2"
        waiting_after: [ "dr2-500"]
        timeout: "1s"
        worker_size: 20
  - name: disk_queue_consumer-prod
    enabled: true
    start:
      joint: disk_queue_consumer
      enabled: true
      parameters:
        input_queue: "prod"
        elasticsearch: "prod"
        waiting_after: [ "prod-500" ]
        timeout: "1s"
        worker_size: 20
  - name: request_logging_index
    enabled: true
    start:
      joint: json_indexing
      enabled: true
      parameters:
        index_name: "gateway_requests"
        elasticsearch: "dr1"
        input_queue: "request_logging"
        timeout: "1s"
        worker_size: 1
        bulk_size_in_mb: 10 #in MB
